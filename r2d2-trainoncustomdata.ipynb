{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/naver/r2d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cd r2d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, pdb\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from tools import common, trainer\n",
    "from tools.dataloader import *\n",
    "from nets.patchnet import *\n",
    "from nets.losses import *\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm.notebook import tqdm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     DataPreparation\n",
    "# except NameError:\n",
    "#     os.system(\"cp -r /kaggle/input/naturalimages/ /tmp/dataset\")\n",
    "#     os.system(\"ln -s /tmp/dataset /kaggle/working/r2d2/data\")\n",
    "#     DataPreparation = True\n",
    "# else:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp -r /kaggle/input/naturalimages/ /tmp/dataset\n",
    "# !ln -s /tmp/dataset /kaggle/working/r2d2/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ls /tmp/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from  datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StillTransform (object):\n",
    "    \"\"\" Takes and return an image, without changing its shape or geometry.\n",
    "    \"\"\"\n",
    "    def _transform(self, img):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __call__(self, inp):\n",
    "        img = F.grab_img(inp)\n",
    "\n",
    "        # transform the image (size should not change)\n",
    "        try:\n",
    "            img = self._transform(img)\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        return F.update_img_and_labels(inp, img, persp=(1,0,0,0,1,0,0,0))\n",
    "\n",
    "    \n",
    "class PixelSpeckleNoise (StillTransform):\n",
    "    \"\"\" Takes an image, and add random white noise.\n",
    "    \"\"\"\n",
    "    def __init__(self, var=.05, seed=None):\n",
    "        StillTransform.__init__(self)\n",
    "        assert 0 <= var < 1\n",
    "        self.var = var\n",
    "        self.seed = seed\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"PixelSpeckleNoise(%g)\" % self.var\n",
    "    \n",
    "    def normalize(self, img,minimum=0, maximum=1):\n",
    "        img_max = np.max(img)\n",
    "        img_min = np.min(img)\n",
    "        return (img-img_min)/np.abs(img_max-img_min)*(maximum-minimum)+minimum\n",
    "\n",
    "    def _transform(self, img):\n",
    "        normalized_img = self.normalize(img)\n",
    "        upper_band = (12*self.var)**.5\n",
    "        np.random.seed(self.seed)\n",
    "        noise = np.random.uniform(-upper_band/2,upper_band/2,size=img.shape)\n",
    "        noisy_img = normalized_img*(1+noise)\n",
    "        noisy_img = np.clip(noisy_img,0,1)\n",
    "        ret_val = self.normalize(noisy_img,maximum=255)\n",
    "        return  Image.fromarray(np.uint8(ret_val))\n",
    "    \n",
    "class PixelNoise (StillTransform):\n",
    "    \"\"\" Takes an image, and add random white noise.\n",
    "    \"\"\"\n",
    "    def __init__(self, ampl=20):\n",
    "        StillTransform.__init__(self)\n",
    "        assert 0 <= ampl < 255\n",
    "        self.ampl = ampl\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"PixelNoise(%g)\" % self.ampl\n",
    "\n",
    "    def _transform(self, img):\n",
    "        img = np.float32(img)\n",
    "        img += np.random.uniform(0.5-self.ampl/2, 0.5+self.ampl/2, size=img.shape)\n",
    "        return Image.fromarray(np.uint8(img.clip(0,255)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_net = \"Quad_L2Net_ConfCFS()\"\n",
    "\n",
    "toy_db_debug = \"\"\"SyntheticPairDataset(\n",
    "    ImgFolder('imgs'), \n",
    "            'RandomScale(256,1024,can_upscale=True)', \n",
    "            'RandomTilting(0.5), PixelSpeckleNoise(.5)')\"\"\"\n",
    "\n",
    "db_web_images = \"\"\"SyntheticPairDataset(\n",
    "    web_images, \n",
    "        'RandomScale(256,1024,can_upscale=True)',\n",
    "        'RandomTilting(0.5), PixelSpeckleNoise(.5)')\"\"\"\n",
    "\n",
    "db_aachen_images = \"\"\"SyntheticPairDataset(\n",
    "    aachen_db_images, \n",
    "        'RandomScale(256,1024,can_upscale=True)', \n",
    "        'RandomTilting(0.5), PixelSpeckleNoise(.5)')\"\"\"\n",
    "\n",
    "db_aachen_style_transfer = \"\"\"TransformedPairs(\n",
    "    aachen_style_transfer_pairs,\n",
    "            'RandomScale(256,1024,can_upscale=True), RandomTilting(0.5), PixelSpeckleNoise(.5)')\"\"\"\n",
    "\n",
    "db_aachen_flow = \"aachen_flow_pairs\"\n",
    "\n",
    "\n",
    "db_sar_images = \"\"\"SyntheticPairDataset(\n",
    "    sar_db_images, \n",
    "        'RandomScale(256,256,can_upscale=False)', \n",
    "        'RandomTilting(0.5), PixelSpeckleNoise(.5)')\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "default_dataloader = \"\"\"PairLoader(CatPairDataset(`data`),\n",
    "    scale   = 'RandomScale(256,1024,can_upscale=True)',\n",
    "    distort = 'ColorJitter(0.2,0.2,0.2,0.1)',\n",
    "    crop    = 'RandomCrop(192)')\"\"\"\n",
    "\n",
    "default_sampler = \"\"\"NghSampler2(ngh=7, subq=-8, subd=1, pos_d=3, neg_d=5, border=16,\n",
    "                            subd_neg=-8,maxpool_pos=True)\"\"\"\n",
    "\n",
    "default_loss = \"\"\"MultiLoss(\n",
    "        1, ReliabilityLoss(`sampler`, base=0.5, nq=20),\n",
    "        1, CosimLoss(N=`N`),\n",
    "        1, PeakyLoss(N=`N`))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sources = dict(\n",
    "    D = toy_db_debug,\n",
    "    W = db_web_images,\n",
    "    A = db_aachen_images,\n",
    "    F = db_aachen_flow,\n",
    "    S = db_aachen_style_transfer,\n",
    "    X = db_sar_images\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyTrainer(trainer.Trainer):\n",
    "    \"\"\" This class implements the network training.\n",
    "        Below is the function I need to overload to explain how to do the backprop.\n",
    "    \"\"\"\n",
    "    def forward_backward(self, inputs):\n",
    "        output = self.net(imgs=[inputs.pop('img1'),inputs.pop('img2')])\n",
    "        allvars = dict(inputs, **output)\n",
    "        loss, details = self.loss_func(**allvars)\n",
    "        if torch.is_grad_enabled(): loss.backward()\n",
    "        return loss, details\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_network(model_fn): \n",
    "    checkpoint = torch.load(model_fn)\n",
    "    print(\"\\n>> Creating net = \" + checkpoint['net']) \n",
    "    net = eval(checkpoint['net'])\n",
    "    nb_of_weights = common.model_size(net)\n",
    "    print(f\" ( Model size: {nb_of_weights/1000:.0f}K parameters )\")\n",
    "\n",
    "    # initialization\n",
    "    weights = checkpoint['state_dict']\n",
    "    net.load_state_dict({k.replace('module.',''):v for k,v in weights.items()})\n",
    "    return net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mkdir trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = \"./trained_models\"\n",
    "gpu = 0\n",
    "train_data = \"WASFX\"\n",
    "data_loader = default_dataloader\n",
    "threads = 8\n",
    "batch_size = 8\n",
    "net = default_net\n",
    "sampler = default_sampler\n",
    "N = patch_size = 16 \n",
    "loss = default_loss\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 5e-4\n",
    "epochs = 10\n",
    "network_path = \"./models/faster2d2_WASF_N16.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching on GPUs 0\n"
     ]
    }
   ],
   "source": [
    "iscuda = common.torch_set_gpu(gpu)\n",
    "common.mkdir_for(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'web_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b924d773f9f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_sources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`data`'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training image database =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreaded_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miscuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'web_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Create data loader\n",
    "db = [data_sources[key] for key in train_data]\n",
    "db = eval(data_loader.replace('`data`',','.join(db)).replace('\\n',''))\n",
    "print(\"Training image database =\", db)\n",
    "loader = threaded_loader(db, iscuda, threads, batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T21:53:43.446293Z",
     "iopub.status.busy": "2022-02-08T21:53:43.445462Z",
     "iopub.status.idle": "2022-02-08T21:53:43.451658Z",
     "shell.execute_reply": "2022-02-08T21:53:43.450977Z",
     "shell.execute_reply.started": "2022-02-08T21:53:43.446245Z"
    }
   },
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T21:53:45.284794Z",
     "iopub.status.busy": "2022-02-08T21:53:45.284137Z",
     "iopub.status.idle": "2022-02-08T21:53:45.321532Z",
     "shell.execute_reply": "2022-02-08T21:53:45.32077Z",
     "shell.execute_reply.started": "2022-02-08T21:53:45.284752Z"
    }
   },
   "outputs": [],
   "source": [
    "net = load_network(network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T21:53:45.485416Z",
     "iopub.status.busy": "2022-02-08T21:53:45.485168Z",
     "iopub.status.idle": "2022-02-08T21:53:45.489551Z",
     "shell.execute_reply": "2022-02-08T21:53:45.488679Z",
     "shell.execute_reply.started": "2022-02-08T21:53:45.485389Z"
    }
   },
   "outputs": [],
   "source": [
    "# # initialization\n",
    "# pretrained = \"./models/faster2d2_WASF_N16.pt\"\n",
    "# checkpoint = torch.load(pretrained, lambda a,b:a)\n",
    "# net.load_pretrained(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T21:53:45.658661Z",
     "iopub.status.busy": "2022-02-08T21:53:45.658404Z",
     "iopub.status.idle": "2022-02-08T21:53:45.668881Z",
     "shell.execute_reply": "2022-02-08T21:53:45.667891Z",
     "shell.execute_reply.started": "2022-02-08T21:53:45.658634Z"
    }
   },
   "outputs": [],
   "source": [
    "# create losses\n",
    "loss = loss.replace('`sampler`',sampler).replace('`N`',str(patch_size))\n",
    "print(\"\\n>> Creating loss = \" + loss)\n",
    "loss = eval(loss.replace('\\n',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T21:53:46.132682Z",
     "iopub.status.busy": "2022-02-08T21:53:46.132079Z",
     "iopub.status.idle": "2022-02-08T21:53:46.144068Z",
     "shell.execute_reply": "2022-02-08T21:53:46.143156Z",
     "shell.execute_reply.started": "2022-02-08T21:53:46.132645Z"
    }
   },
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = optim.Adam( [p for p in net.parameters() if p.requires_grad], \n",
    "                        lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "train = MyTrainer(net, loader, loss, optimizer)\n",
    "if iscuda: train = train.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T21:53:46.890952Z",
     "iopub.status.busy": "2022-02-08T21:53:46.890147Z",
     "iopub.status.idle": "2022-02-08T21:54:13.154465Z",
     "shell.execute_reply": "2022-02-08T21:54:13.151761Z",
     "shell.execute_reply.started": "2022-02-08T21:53:46.890903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training loop #\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n>> Starting epoch {epoch}...\")\n",
    "    train()\n",
    "\n",
    "print(f\"\\n>> Saving model to {save_path}\")\n",
    "torch.save({'net': args.net, 'state_dict': net.state_dict()}, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
